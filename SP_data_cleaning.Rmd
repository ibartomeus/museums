---
title: "SP"
author: "I. Bartomeus"
date: "05/10/2017"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Notas:

- 'Localidades?': Info per species. Recorded only at the first record of each species. Refers to geograpfic known records. Usefull for abejassilvestres.es ?
- 'obrera' needs to be merged with 'sex'
- ID and 'cuaderno' need to remove duplicates, which are not in cuaderno!!
- IF several IT's Oscar Aguado duplicated the enetry as many times as need. Those sp are in red in original excel.


Old data:

```{r}
sp <- read.csv(file = "raw_data/Spain.csv", h = T)
head(sp)
head(sort(table(sp$LOCALIDAD), decreasing = TRUE))
#write.csv(sort(table(sp$LOCALIDAD), decreasing = TRUE),
 #         "raw_data/localidades.csv")

sp$gen_sp <- paste(sp$G.NERO, sp$ESPECIE, sep = "_")
unique(sp$gen_sp) #721 species! #clean, but only for the subset of used data. The 7 localities.
head(sort(table(sp$gen_sp), decreasing = TRUE), 50)

#subset only the 7 localities.
tesaurus <- read.csv("data/Locations.csv")
head(tesaurus)
levels(tesaurus$Localidad_Oscar) <- c("auditorio_Delibes",
                                      "hornillos",
                                      "hornillos",
                                      "olmedo",
                                      "olmedo",
                                      "sanbernardo",
                                      "toro",
                                      "toro",
                                      "vilalba",
                                      "zamaduenas")
#merge
sp2 <- merge(sp, tesaurus, by.x = "LOCALIDAD", by.y = "Localidad_asensio")
head(sp2)

#check sampling completness
library(vegan)
#need to fix first locality
head(sp2)
comm <- table(sp2$Localidad_Oscar, sp2$gen_sp)
temp <- specaccum(comm, "random")
summary(temp)
plot(temp)
rarecurve(comm)

```

New data:

```{r}
now <- read.csv(file = "raw_data/Spain_2016.csv", h = T)
head(now)
table(now$LOCALIDAD)
levels(now$LOCALIDAD) <- c("auditorio_Delibes",
                           "auditorio_Delibes",
                           "hornillos",
                           "hornillos",
                           "olmedo",
                           "sanbernardo",
                           "toro",
                           "vilalba",
                           "zamaduenas")
#get lat long
library(spatial)
#biogeomancer(country = "Spain", adm1 = "Castilla y Leon", adm2 = "Valladolid", 
#             locality = levels(now$LOCALIDAD), 
#             singleRecord=TRUE, progress="text")
#not working, but Ropen sci has alternative packages.
now$gen_sp <- paste(now$GÃ‰NERO, now$ESPECIE, sep = "_")
sort(table(now$gen_sp))
#clean species
unique(now$gen_sp) #197!!! but still some duplicates 

#check sampling completness
library(vegan)
comm <- table(now$LOCALIDAD, now$gen_sp)
temp <- specaccum(comm, "random")
summary(temp)
plot(temp)
rarecurve(comm) #uf... not really well sampled... but ~80 species per site it's quite good!
```

Data Gbif:
```{r}
gbif <- read.csv(file = "raw_data/data_gbif.csv", h = T)
head(gbif)
hist(gbif$year) #nice, bimodal!
sort(table(gbif$recordedBy), decreasing = TRUE)
#Engel, M, Hinojosa, I, Bennett, D, & Davis, S
#G.E. Bohart
#Torchio, Asensio, etc...
#Baker, D. & Baker, M.
# see
set <- which(gbif$recordedBy == "Engel, M, Hinojosa, I, Bennett, D, & Davis, S")
library(mapr)
colnames(gbif)[2:3] <- c("latitude", "longitude") 
map_leaflet(gbif[set,]) #interesting, 
# Engel collected in 2007 in the south! And taxonomy is bad!
# Baker in Estartit #del 62! 
# Bohart Madrid, islands, south... in 78's

#Overall, most pre 1980 collections around valladolid.
head(sort(table(gbif$species), decreasing = TRUE), 50)
unique(gbif$species) #443! BUT here lots of duplicates?
```

#Analysis

```{r}
#make final dataset
sp3 <- sp2[,c("Localidad_Oscar", "gen_sp", "NUM_EJEMPLARES")]
colnames(sp3)[1] <- "LOCALIDAD"
now3 <- now[, c("LOCALIDAD", "gen_sp")]
now3$NUM_EJEMPLARES <- 1
now3$when <- "now"
sp3$when <- "asensio"

library(lettercase)
str_ucfirst(str_lower_case(sp3$gen_sp[1:10]))


sp3$gen_sp <- str_ucfirst(str_lower_case(sp3$gen_sp))

dat <- rbind(sp3, now3)
#check stuff
head(dat)
unique(dat$gen_sp) #429
#this can be cleaned, but looks decent!

colnames(dat) <- c("locality", "gen_sp", "freq", "when")
#freq should be melted.

unique(dat$locality) #8
str(dat)
write.csv(dat, "data/spain_clean.csv", row.names = F)
```


1) only for 7 localities, join now and then and paired t-test on rarefied richness per site

1.1) Show raref per site

2) For common species we can do the same but with standardized frequency.


```{r}
dat <- read.csv("data/spain_clean.csv")
#head(dat)
library(reshape2)
#dat2 <- melt(dat, id.vars = c("locality", "gen_sp", "when"), 
 #            measure.vars = "freq")
#head(dat2, 100)
#sort(unique(dat2$gen_sp))
#clean with clean_sp
dat$gen_sp <- gsub(x = dat$gen_sp, pattern = " ", replacement = "", fixed = TRUE)
#sort(unique(dat$gen_sp))
dat$gen_sp <- gsub(x = dat$gen_sp, pattern = "_", replacement = " ", fixed = TRUE)
#remove sp, NA,
#NA_NA   
#Hylaeus_Variegatus
#source("clean_species.R") #sourced from Evenness project.
library(taxize)
spp <- clean_species(dat$gen_sp, rows = 1)
species <- dat$gen_sp
#table(dat2$gen_sp, dat2$when)
#Andrena_pilipes = carbonaria
#remove A. mellifera
rich_tot <- dcast(dat, when ~ ., value.var = "gen_sp", 
              fun.aggregate = function(x) length(unique(x)))
rich_tot #wow.
#extract genus
pos <- regexpr(dat$gen_sp, pattern = " ", fixed = TRUE)
dat$genus <- substr(dat$gen_sp, 
                    start = 1,
                    stop = pos-1)
genus_tot <- dcast(dat, when ~ ., value.var = "genus", 
              fun.aggregate = function(x) length(unique(x)))
genus_tot2 <- dcast(dat,  genus ~ when, value.var = "genus", 
              fun.aggregate = function(x) length(unique(x)))
genus_tot #wow, reversed??
genus_tot2
subset(genus_tot2, now == 0 & asensio == 1)
subset(genus_tot2, now == 1 & asensio == 1)
subset(genus_tot2, now == 1 & asensio == 0)

#remove non apis genus! check with Curro.

#losts easely spotted: nomadas & Tyreus, prosopis, teralonias

#calculate richness per site and time period
#head(dat)
rich <- dcast(dat, locality ~ when, value.var = "gen_sp", 
              fun.aggregate = function(x) length(unique(x)))
#rich
#t.test(rich$asensio, rich$now, paired = TRUE)

boxplot(rich$asensio[c(1,2,3,5,6,7)], rich$now[c(1,2,3,5,6,7)], names = c("1980's", "2016"), ylab = "species richness", 
            las = 1, border = "light grey")
points(x = c(rep(1,6), rep (2,6)), y = c(rich$asensio[c(1,2,3,5,6,7)],
                                         rich$now[c(1,2,3,5,6,7)]), col = rep(c(1,2,3,5,6,7),2), pch = 19)
for(i in c(1,2,3,5,6,7)){
    lines(x = 1:2, y = c(rich$asensio[i], rich$now[i]), col = i)
}

library(vegan)
temp <- subset(dat, when == "now")
comm <- dcast(temp, locality ~ gen_sp, value.var = "freq", 
              fun.aggregate = sum, na.rm = TRUE)
rownames(comm)[-8] <- as.character(comm$locality[-8])
comm2 <- comm[,-1] 
#rowSums(comm2) #toro is low, but same sampling effort. 
temp <- specaccum(comm2, "random")
#plot(temp)
#rarecurve(comm2)
now <- rarefy(x = comm2, sample = 120)

temp <- subset(dat, when == "asensio")
comm <- dcast(temp, locality ~ gen_sp, value.var = "freq", 
              fun.aggregate = sum, na.rm = TRUE)
#comm <- dcast(temp, locality ~ gen_sp, value.var = "freq", 
 #             fun.aggregate = length, na.rm = TRUE)
rownames(comm)[-8] <- as.character(comm$locality[-8])
comm2 <- comm[,-1]
#rowSums(comm2) #sanbernardo useless. Others ok! Delives super sampled!!
temp <- specaccum(comm2, "random")
#plot(temp)
#rarecurve(comm2) #for delives quite complete!
asensio <- rarefy(x = comm2, sample = 120)

ttest <- t.test(asensio[c(1,2,3,5,6,7)], now[c(1,2,3,5,6,7)], paired = TRUE)

boxplot(asensio[c(1,2,3,5,6,7)], now[c(1,2,3,5,6,7)], names = c("1980's", "2016"), ylab = "rarefied species richness", 
            las = 1, border = "light grey")
points(x = c(rep(1,6), rep (2,6)), y = c(asensio[c(1,2,3,5,6,7)], now[c(1,2,3,5,6,7)]), col = rep(c(1,2,3,5,6,7),2), pch = 19)
for(i in c(1,2,3,5,6,7)){
    lines(x = 1:2, y = c(asensio[i], now[i]), col = i)
}


#do by coverage?
#clean sp.
```







